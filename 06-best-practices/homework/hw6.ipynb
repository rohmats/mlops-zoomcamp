{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1. Refactoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to create the \"main\" block from which we'll invoke the main function. How does the if statement that we use for this looks like?\n",
    "\n",
    "`if __name__ == \"__main__\":`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code `batch.py ` for Q1\n",
    "<details>\n",
    "<summary>Click to show/hide code</summary>\n",
    "\n",
    "```python\n",
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "import warnings\n",
    "import sys\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import click\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='sklearn')\n",
    "\n",
    "\n",
    "def generate_output_file_path(year, month):\n",
    " return f'./output/yellow_tripdata_{year:04d}-{month:02d}.parquet'\n",
    "\n",
    "\n",
    "def read_data(filename, categorical):\n",
    "    df = pd.read_parquet(filename)\n",
    "\n",
    "    df['duration'] = df.tpep_dropoff_datetime - df.tpep_pickup_datetime\n",
    "    df['duration'] = df.duration.dt.total_seconds() / 60\n",
    "\n",
    "    df = df[(df.duration >= 1) & (df.duration <= 60)].copy()\n",
    "\n",
    "    df[categorical] = df[categorical].fillna(-1).astype('int').astype('str')\n",
    "\n",
    "    return df, categorical\n",
    "\n",
    "@click.command()\n",
    "@click.option(\n",
    "    '--year',\n",
    "    type=int,\n",
    "    required=True,\n",
    "    help='Year of the trip data'\n",
    ")\n",
    "@click.option(\n",
    "    '--month',\n",
    "    type=int,\n",
    "    required=True,\n",
    "    help='Month of the trip data'\n",
    ")\n",
    "def main(year, month):\n",
    "    with open('./model.bin', 'rb') as f_in:\n",
    "        dv, lr = pickle.load(f_in)\n",
    "\n",
    "    input_file = f'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_{year:04d}-{month:02d}.parquet'\n",
    "    df, categorical = read_data(input_file, categorical = ['PULocationID', 'DOLocationID'])\n",
    "\n",
    "    df['ride_id'] = f'{year:04d}/{month:02d}_' + df.index.astype('str')\n",
    "\n",
    "    dicts = df[categorical].to_dict(orient='records')\n",
    "    X_val = dv.transform(dicts)\n",
    "    y_pred = lr.predict(X_val)\n",
    "\n",
    "    print('predicted mean duration:', y_pred.mean())\n",
    "\n",
    "\n",
    "    df_result = pd.DataFrame()\n",
    "    df_result['ride_id'] = df['ride_id']\n",
    "    df_result['predicted_duration'] = y_pred\n",
    "\n",
    "    output_file = generate_output_file_path(year, month)\n",
    "    df_result.to_parquet(output_file, engine='pyarrow', index=False)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir -p output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted mean duration: 14.292282936862449\n"
     ]
    }
   ],
   "source": [
    "! python batch.py --year 2023 --month 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".  ..  yellow_tripdata_2023-04.parquet\n"
     ]
    }
   ],
   "source": [
    "! ls ./output -a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2. Installing pytest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, create a folder tests and create two files. One will be the file with tests. We can name it test_batch.py.\n",
    "\n",
    "What should be the other file?\n",
    "\n",
    " `__init__.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install `pytest` to pipenv -dev\n",
    "```bash\n",
    "pipenv install --dev pytest\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir -p tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "! touch tests/__init__.py tests/test_batch.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".  ..  __init__.py  test_batch.py\n"
     ]
    }
   ],
   "source": [
    "! ls ./tests -a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3. Writing first unit test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many rows should be there in the expected dataframe?\n",
    "\n",
    "* 1\n",
    "* 2 âœ…\n",
    "* 3\n",
    "* 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code `batch.py` for Q3:\n",
    "<details>\n",
    "<summary>Click to show/hide code</summary>\n",
    "\n",
    "```python\n",
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "import warnings\n",
    "import sys\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import click\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='sklearn')\n",
    "\n",
    "\n",
    "def generate_output_file_path(year, month):\n",
    " return f'./output/yellow_tripdata_{year:04d}-{month:02d}.parquet'\n",
    "\n",
    "\n",
    "def prepare_data(df, categorical):\n",
    "    df['duration'] = df.tpep_dropoff_datetime - df.tpep_pickup_datetime\n",
    "    df['duration'] = df.duration.dt.total_seconds() / 60\n",
    "    df = df[(df.duration >= 1) & (df.duration <= 60)].copy()\n",
    "\n",
    "    df[categorical] = df[categorical].fillna(-1).astype('int').astype('str')\n",
    "    return df, categorical\n",
    "\n",
    "\n",
    "def read_data(filename, categorical):\n",
    "    df = pd.read_parquet(filename)\n",
    "    return prepare_data(df, categorical)\n",
    "\n",
    "\n",
    "@click.command()\n",
    "@click.option(\n",
    "    '--year',\n",
    "    type=int,\n",
    "    required=True,\n",
    "    help='Year of the trip data'\n",
    ")\n",
    "@click.option(\n",
    "    '--month',\n",
    "    type=int,\n",
    "    required=True,\n",
    "    help='Month of the trip data'\n",
    ")\n",
    "def main(year, month):\n",
    "    with open('./model.bin', 'rb') as f_in:\n",
    "        dv, lr = pickle.load(f_in)\n",
    "\n",
    "    input_file = f'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_{year:04d}-{month:02d}.parquet'\n",
    "    df, categorical = read_data(input_file, categorical = ['PULocationID', 'DOLocationID'])\n",
    "\n",
    "    df['ride_id'] = f'{year:04d}/{month:02d}_' + df.index.astype('str')\n",
    "\n",
    "    dicts = df[categorical].to_dict(orient='records')\n",
    "    X_val = dv.transform(dicts)\n",
    "    y_pred = lr.predict(X_val)\n",
    "\n",
    "    print('predicted mean duration:', y_pred.mean())\n",
    "\n",
    "    df_result = pd.DataFrame()\n",
    "    df_result['ride_id'] = df['ride_id']\n",
    "    df_result['predicted_duration'] = y_pred\n",
    "\n",
    "    output_file = generate_output_file_path(year, month)\n",
    "    df_result.to_parquet(output_file, engine='pyarrow', index=False)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "    \n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted mean duration: 14.292282936862449\n"
     ]
    }
   ],
   "source": [
    "! python batch.py --year 2023 --month 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for `tests/test_batch.py`\n",
    "\n",
    "<details>\n",
    "<summary>Click to show/hide code</summary>\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "from batch import prepare_data\n",
    "\n",
    "\n",
    "def dt(hour, minute, second=0):\n",
    "    return datetime(2023, 1, 1, hour, minute, second)\n",
    "\n",
    "\n",
    "def prepare_test_data():\n",
    "    data = [\n",
    "    (None, None, dt(1, 1), dt(1, 10)),\n",
    "    (1, 1, dt(1, 2), dt(1, 10)),\n",
    "    (1, None, dt(1, 2, 0), dt(1, 2, 59)),\n",
    "    (3, 4, dt(1, 2, 0), dt(2, 2, 1))\n",
    "    ]\n",
    "\n",
    "    columns_test_df = ['PULocationID', 'DOLocationID', 'tpep_pickup_datetime', 'tpep_dropoff_datetime']\n",
    "    test_df = pd.DataFrame(data, columns=columns_test_df)\n",
    "\n",
    "    categorical = ['PULocationID', 'DOLocationID']\n",
    "\n",
    "    prepared_test_df, categorical = prepare_data(test_df, categorical)\n",
    "    print(prepared_test_df)\n",
    "\n",
    "    expected_prepared_test_df = [\n",
    "        ('-1', '-1', 9.),\n",
    "        ('1', '1', 8.),\n",
    "    ]\n",
    "    columns_expected_df = ['PULocationID', 'DOLocationID', 'duration']\n",
    "    expected_prepared_test_df = pd.DataFrame(expected_prepared_test_df, columns=columns_expected_df)\n",
    "\n",
    "    catigorial_cols = ['PULocationID', 'DOLocationID']\n",
    "    for col in catigorial_cols:\n",
    "        assert (prepared_test_df[col] == expected_prepared_test_df[col]).all()\n",
    "\n",
    "    float_cols = ['duration']\n",
    "    epsilon = 1e-9\n",
    "    for col in float_cols:\n",
    "        np.allclose(prepared_test_df[col], expected_prepared_test_df[col], atol=epsilon)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tests.test_batch import prepare_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  PULocationID DOLocationID tpep_pickup_datetime tpep_dropoff_datetime  \\\n",
      "0           -1           -1  2023-01-01 01:01:00   2023-01-01 01:10:00   \n",
      "1            1            1  2023-01-01 01:02:00   2023-01-01 01:10:00   \n",
      "\n",
      "   duration  \n",
      "0       9.0  \n",
      "1       8.0  \n"
     ]
    }
   ],
   "source": [
    "prepare_test_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4. Mocking S3 with Localstack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* --backend-store-uri\n",
    "* --profile\n",
    "* --endpoint-url âœ…\n",
    "* --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "! touch docker-compose.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code `docker-compose.yaml`\n",
    "<details>\n",
    "<summary>Click to show/hide code</summary>\n",
    "\n",
    "```YAML\n",
    "services:\n",
    "  localstack:\n",
    "    image: localstack/localstack\n",
    "    container_name: localstack\n",
    "    ports:\n",
    "      - \"4566:4566\"\n",
    "    environment:\n",
    "      - SERVICES=s3\n",
    "      - DEBUG=1\n",
    "      - AWS_ACCESS_KEY_ID=dummyAccessKeyId\n",
    "      - AWS_SECRET_ACCESS_KEY=dummySecretAccessKey\n",
    "      - DEFAULT_REGION=us-east-1\n",
    "    volumes:\n",
    "      - \"./localstack:/var/lib/localstack\"\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build localstack docker image\n",
    "\n",
    "`docker compose up -d --build`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare dummy AWS credentials\n",
    "```batch\n",
    "mkdir -p ~/.aws\n",
    "nano ~/.aws/credentials\n",
    "```\n",
    "\n",
    "Code for `~/.aws/credentials`\n",
    "<details>\n",
    "<summary>Click to show/hide code</summary>\n",
    "\n",
    "```\n",
    "[default]\n",
    "aws_access_key_id = foo\n",
    "aws_secret_access_key = bar\n",
    "```\n",
    "</details>\n",
    "\n",
    "Set AWS Configuration\n",
    "```batch\n",
    "nano ~/.aws/config\n",
    "```\n",
    "\n",
    "Code for `~/.aws/config`\n",
    "<details>\n",
    "<summary>Click to show/hide code</summary>\n",
    "\n",
    "```\n",
    "[default]\n",
    "region = us-east-1\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install AWS CLI\n",
    "\n",
    "`pipenv install awscli`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws-cli/1.33.22 Python/3.10.13 Linux/6.5.0-1022-azure botocore/1.34.131\n"
     ]
    }
   ],
   "source": [
    "! aws --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make_bucket: nyc-duration\n"
     ]
    }
   ],
   "source": [
    "! aws --endpoint-url=http://localhost:4566 s3 mb s3://nyc-duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "year, month =  2023, 4\n",
    "\n",
    "input_file = f'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_{year:04d}-{month:02d}.parquet'\n",
    "df = pd.read_parquet(input_file)\n",
    "\n",
    "\n",
    "s3_endpoint_url=\"http://localhost:4566\"\n",
    "input_file=f\"s3://nyc-duration/in/{year:04d}-{month:02d}.parquet\"\n",
    "\n",
    "storage_options = {'client_kwargs': {'endpoint_url': s3_endpoint_url}}\n",
    "df.to_parquet(input_file, engine='pyarrow', index=False, storage_options=storage_options)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code `batch.py` for Q4\n",
    "<details>\n",
    "<summary>Click to show/hide code</summary>\n",
    "\n",
    "```python\n",
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "import warnings\n",
    "import sys\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import click\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='sklearn')\n",
    "\n",
    "\n",
    "def get_input_path(year, month):\n",
    "    default_input_pattern = 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_{year:04d}-{month:02d}.parquet'\n",
    "    input_pattern = os.getenv('INPUT_FILE_PATTERN', default_input_pattern)\n",
    "    return input_pattern.format(year=year, month=month)\n",
    "\n",
    "def get_output_path(year, month):\n",
    "    default_output_pattern = './output/yellow_tripdata_{year:04d}-{month:02d}.parquet'\n",
    "    output_pattern = os.getenv('OUTPUT_FILE_PATTERN', default_output_pattern)\n",
    "    return output_pattern.format(year=year, month=month)\n",
    "\n",
    "def prepare_data(df, categorical):\n",
    "    df['duration'] = df.tpep_dropoff_datetime - df.tpep_pickup_datetime\n",
    "    df['duration'] = df.duration.dt.total_seconds() / 60\n",
    "    df = df[(df.duration >= 1) & (df.duration <= 60)].copy()\n",
    "\n",
    "    df[categorical] = df[categorical].fillna(-1).astype('int').astype('str')\n",
    "    return df, categorical\n",
    "\n",
    "def read_data(year, month, categorical):\n",
    "    options = {}\n",
    "    s3_endpoint_url = os.getenv('S3_ENDPOINT_URL')\n",
    "    input_pattern = os.getenv('INPUT_FILE_PATTERN')\n",
    "    input_file = get_input_path(year, month)\n",
    "\n",
    "    if s3_endpoint_url and input_pattern:\n",
    "        options['storage_options'] = {'client_kwargs': {'endpoint_url': s3_endpoint_url}}\n",
    "        df = pd.read_parquet(input_file, storage_options=options['storage_options'])\n",
    "        print(f'Data loaded from S3, INPUT_FILE_PATTERN is {input_pattern}')\n",
    "    else:\n",
    "        print('else')\n",
    "        df = pd.read_parquet(input_file)\n",
    "        print(f'Data loaded from the internet, INPUT_FILE_PATTERN is {input_pattern}')\n",
    "    return prepare_data(df, categorical)\n",
    "\n",
    "def save_parquet_to_s3(output_file, df):\n",
    "    s3_endpoint_url = os.getenv('S3_ENDPOINT_URL')\n",
    "    output_pattern = os.getenv('OUTPUT_FILE_PATTERN')\n",
    "    options = {}\n",
    "    if s3_endpoint_url and output_pattern:\n",
    "        options['storage_options'] = {'client_kwargs': {'endpoint_url': s3_endpoint_url}}\n",
    "        df.to_parquet(output_file, engine='pyarrow', index=False, storage_options=options['storage_options'])\n",
    "        print(f'File saved to S3, OUTPUT_FILE_PATTERN is {output_pattern}')\n",
    "    else:\n",
    "        df.to_parquet(output_file, engine='pyarrow', index=False)\n",
    "        print(f'File saved locally, OUTPUT_FILE_PATTERN is {output_pattern}')\n",
    "\n",
    "\n",
    "@click.command()\n",
    "@click.option(\n",
    "    '--year',\n",
    "    type=int,\n",
    "    required=True,\n",
    "    help='Year of the trip data'\n",
    ")\n",
    "@click.option(\n",
    "    '--month',\n",
    "    type=int,\n",
    "    required=True,\n",
    "    help='Month of the trip data'\n",
    ")\n",
    "def main(year, month):\n",
    "    with open('./model.bin', 'rb') as f_in:\n",
    "        dv, lr = pickle.load(f_in)\n",
    "\n",
    "    df, categorical = read_data(year, month, categorical = ['PULocationID', 'DOLocationID'])\n",
    "\n",
    "    df['ride_id'] = f'{year:04d}/{month:02d}_' + df.index.astype('str')\n",
    "\n",
    "    dicts = df[categorical].to_dict(orient='records')\n",
    "    X_val = dv.transform(dicts)\n",
    "    y_pred = lr.predict(X_val)\n",
    "\n",
    "    print('predicted mean duration:', y_pred.mean())\n",
    "\n",
    "    df_result = pd.DataFrame()\n",
    "    df_result['ride_id'] = df['ride_id']\n",
    "    df_result['predicted_duration'] = y_pred\n",
    "\n",
    "    output_file = get_output_path(year, month)\n",
    "    save_parquet_to_s3(output_file, df_result)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "! touch run_batch_py_local.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code `run_batch_py_local.sh`\n",
    "<details>\n",
    "<summary>Click to show/hide code</summary>\n",
    "\n",
    "```shell\n",
    "#!/bin/bash\n",
    "\n",
    "# Set environment variables\n",
    "export INPUT_FILE_PATTERN=\"s3://nyc-duration/in/{year:04d}-{month:02d}.parquet\"\n",
    "export OUTPUT_FILE_PATTERN=\"s3://nyc-duration/out/{year:04d}-{month:02d}.parquet\"\n",
    "export S3_ENDPOINT_URL=\"http://localhost:4566\"\n",
    "\n",
    "# Run the Python script with parameters\n",
    "python batch.py --year 2023 --month 4\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "! chmod +x run_batch_py_local.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded from S3, INPUT_FILE_PATTERN is s3://nyc-duration/in/{year:04d}-{month:02d}.parquet\n",
      "predicted mean duration: 14.292282936862449\n",
      "File saved to S3, OUTPUT_FILE_PATTERN is s3://nyc-duration/out/{year:04d}-{month:02d}.parquet\n"
     ]
    }
   ],
   "source": [
    "! ./run_batch_py_local.sh"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
